

************************

(a)
NB: a Gaussian Naive Bayes Classifier with the default parameters

(b)
[[ 4  0  0  0  0]
 [ 1  4  0  0  0]
 [ 0  0  5  0  0]
 [ 0  0  0 11  0]
 [ 4  1  1  0 19]]

(c)
              precision    recall  f1-score   support

       drugA       0.44      1.00      0.62         4
       drugB       0.80      0.80      0.80         5
       drugC       0.83      1.00      0.91         5
       drugX       1.00      1.00      1.00        11
       drugY       1.00      0.76      0.86        25

    accuracy                           0.86        50
   macro avg       0.82      0.91      0.84        50
weighted avg       0.92      0.86      0.87        50


(d)
Accuracy score: 0.86
Macro-average F1 score: 0.84
Weighted-average F1 score: 0.87

************************

(a)
Base-DT: a Decision Tree with the default parameters

(b)
[[ 4  0  0  0  0]
 [ 1  4  0  0  0]
 [ 0  0  5  0  0]
 [ 0  0  0 11  0]
 [ 0  0  0  0 25]]

(c)
              precision    recall  f1-score   support

       drugA       0.80      1.00      0.89         4
       drugB       1.00      0.80      0.89         5
       drugC       1.00      1.00      1.00         5
       drugX       1.00      1.00      1.00        11
       drugY       1.00      1.00      1.00        25

    accuracy                           0.98        50
   macro avg       0.96      0.96      0.96        50
weighted avg       0.98      0.98      0.98        50


(d)
Accuracy score: 0.98
Macro-average F1 score: 0.96
Weighted-average F1 score: 0.98

************************

(a)
'Top-DT' a better performing Decision Tree with the following hyper-parameters:
{'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 3}

(b)
[[ 4  0  0  0  0]
 [ 1  4  0  0  0]
 [ 0  0  5  0  0]
 [ 0  0  0 11  0]
 [ 0  0  0  0 25]]

(c)
              precision    recall  f1-score   support

       drugA       0.80      1.00      0.89         4
       drugB       1.00      0.80      0.89         5
       drugC       1.00      1.00      1.00         5
       drugX       1.00      1.00      1.00        11
       drugY       1.00      1.00      1.00        25

    accuracy                           0.98        50
   macro avg       0.96      0.96      0.96        50
weighted avg       0.98      0.98      0.98        50


(d)
Accuracy score: 0.98
Macro-average F1 score: 0.96
Weighted-average F1 score: 0.98

************************

(a)
PER: a Perceptron, with default parameter values

(b)
[[ 2  0  0  0  2]
 [ 1  0  0  2  2]
 [ 0  0  0  1  4]
 [ 0  0  0  1 10]
 [ 0  0  0  0 25]]

(c)
              precision    recall  f1-score   support

       drugA       0.67      0.50      0.57         4
       drugB       0.00      0.00      0.00         5
       drugC       0.00      0.00      0.00         5
       drugX       0.25      0.09      0.13        11
       drugY       0.58      1.00      0.74        25

    accuracy                           0.56        50
   macro avg       0.30      0.32      0.29        50
weighted avg       0.40      0.56      0.44        50


(d)
Accuracy score: 0.56
Macro-average F1 score: 0.29
Weighted-average F1 score: 0.44

************************

(a)
Base-MLP: a Multi-Layered Perceptron with 1 hidden layer of 100 neurons, sigmoid/logistic as activation function, stochastic gradient descent, and default values for the rest of the parameters.
Also adjusted max_iter=5000 to converge.

(b)
[[ 0  0  0  3  1]
 [ 0  0  0  5  0]
 [ 0  0  0  3  2]
 [ 1  0  0  8  2]
 [ 0  0  0  1 24]]

(c)
              precision    recall  f1-score   support

       drugA       0.00      0.00      0.00         4
       drugB       0.00      0.00      0.00         5
       drugC       0.00      0.00      0.00         5
       drugX       0.40      0.73      0.52        11
       drugY       0.83      0.96      0.89        25

    accuracy                           0.64        50
   macro avg       0.25      0.34      0.28        50
weighted avg       0.50      0.64      0.56        50


(d)
Accuracy score: 0.64
Macro-average F1 score: 0.28
Weighted-average F1 score: 0.56

************************

(a)
'Top-MLP' a better performing Multi-Layered Perceptron found using grid search with the following hyper-parameters:
{'activation': 'identity', 'hidden_layer_sizes': (30, 50), 'solver': 'adam'}

(b)
[[ 0  0  0  4  0]
 [ 0  0  0  5  0]
 [ 0  0  0  3  2]
 [ 1  0  0  9  1]
 [ 0  0  0  5 20]]

(c)
              precision    recall  f1-score   support

       drugA       0.00      0.00      0.00         4
       drugB       0.00      0.00      0.00         5
       drugC       0.00      0.00      0.00         5
       drugX       0.35      0.82      0.49        11
       drugY       0.87      0.80      0.83        25

    accuracy                           0.58        50
   macro avg       0.24      0.32      0.26        50
weighted avg       0.51      0.58      0.52        50


(d)
Accuracy score: 0.58
Macro-average F1 score: 0.26
Weighted-average F1 score: 0.52

'''
Q8 -
'''


NB: a Gaussian Naive Bayes Classifier with the default parameters

Average accuracy score: 0.86
Average macro-average F1 score: 0.84
Average weighted-average F1 score: 0.87
Accuracy standard deviation: 0.00
Macro F1 standard deviation: 0.00
Weighted F1 standard deviation: 0.00

Base-DT: a Decision Tree with the default parameters

Average accuracy score: 0.98
Average macro-average F1 score: 0.96
Average weighted-average F1 score: 0.98
Accuracy standard deviation: 0.00
Macro F1 standard deviation: 0.00
Weighted F1 standard deviation: 0.00

Top-DT: a better performing Decision Tree

Average accuracy score: 0.98
Average macro-average F1 score: 0.96
Average weighted-average F1 score: 0.98
Accuracy standard deviation: 0.00
Macro F1 standard deviation: 0.00
Weighted F1 standard deviation: 0.00

PER: a Perceptron, with default parameter values

Average accuracy score: 0.56
Average macro-average F1 score: 0.29
Average weighted-average F1 score: 0.44
Accuracy standard deviation: 0.00
Macro F1 standard deviation: 0.00
Weighted F1 standard deviation: 0.00

Base-MLP: a Multi-Layered Perceptron with 1 hidden layer of 100 neurons, sigmoid/logistic as activation function, stochastic gradient descent, and default values for the rest of the parameters.

Average accuracy score: 0.66
Average macro-average F1 score: 0.29
Average weighted-average F1 score: 0.57
Accuracy standard deviation: 0.01
Macro F1 standard deviation: 0.00
Weighted F1 standard deviation: 0.00

Top-MLP: a better performing Multi-Layered Perceptron found using grid search

Average accuracy score: 0.91
Average macro-average F1 score: 0.85
Average weighted-average F1 score: 0.90
Accuracy standard deviation: 0.14
Macro F1 standard deviation: 0.23
Weighted F1 standard deviation: 0.17